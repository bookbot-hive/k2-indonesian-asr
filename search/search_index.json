{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kaldi 2.0 Indonesian ASR","text":"<p>Indonesian speech/phoneme recognizer powered by Kaldi 2.0 (lhotse, icefall, sherpa). Trained on open source speech data. Deployable on Desktop (via Python/C++), web apps, iOS, and Android.</p> <p>All models released here are trained on icefall (which runs on PyTorch) and are converted for deployment via sherpa-ncnn. Icefall is Kaldi 2.0 / Next-Gen Kaldi, and unifies the application of k2 for finite state automata (FSA) and lhotse (audio data-loading).</p> <p>Through this repository, we aim to document and release our open source models for the public's use.</p>"},{"location":"#training-dataset","title":"Training Dataset","text":"<p>As of the time of writing, we use the following datasets to train our models:</p> <ul> <li>Common Voice ID</li> <li>LibriVox Indonesia</li> <li>FLEURS ID</li> </ul> <p>Noticeably, these datasets only contain text annotations and do not contain phoneme annotations. We used g2p ID to phonemize those text annotations.</p> <p>Moreover, LibriVox Indonesia's original annotation is written with old Indonesian Republican Spelling System (Edjaan Repoeblik). We pre-converted them into EYD (Ejaan yang Disempurnakan) via Doeloe, before phonemizing them.</p>"},{"location":"#available-models","title":"Available Models","text":""},{"location":"#pruned-stateless-zipformer-rnn-t-streaming-id-phonemes","title":"Pruned Stateless Zipformer RNN-T Streaming ID (Phonemes)","text":"Model Format Link Icefall Pruned Stateless Zipformer RNN-T Streaming ID Sherpa NCNN Sherpa-ncnn Pruned Stateless Zipformer RNN-T Streaming ID Sherpa ONNX TBA <p>Results (PER)</p> Decoding LibriVox FLEURS Common Voice Greedy Search 4.87% 11.45% 14.97% Modified Beam Search 4.71% 11.25% 14.31% Fast Beam Search 4.85% 12.55% 14.89%"},{"location":"#usage","title":"Usage","text":"<p>There are various ways to export and deploy these models for production. Sherpa (Kaldi 2.0's main deployment framework) also has various counterparts for running on NCNN and/or ONNX engines. Or, you can also directly use these models via icefall, but they require a working PyTorch installation and is unoptimized for production.</p> <p>We will provide a few external links to Sherpa's thorough documentation which you can follow. We will also provide usage examples for Recognize a file and Real-time recognition with a microphone in Python.</p> Inference Framework Platform Language Link Sherpa Desktop C++ Guide Sherpa NCNN Desktop Python Guide Sherpa NCNN Android Kotlin Guide Sherpa NCNN iOS Swift Guide Sherpa ONNX Desktop Python Guide Sherpa ONNX Android Kotlin Guide Sherpa ONNX iOS Swift Guide"},{"location":"#example-recognize-a-file-python-sherpa-ncnn","title":"Example: Recognize a File (Python - Sherpa NCNN)","text":"<p>The following code is adapted from this example. View this example running in our live demo!</p> <pre><code>import wave\nimport numpy as np\nimport sherpa_ncnn\npath = \"./sherpa-ncnn-pruned-transducer-stateless7-streaming-id\"\ndef main():\nrecognizer = sherpa_ncnn.Recognizer(\ntokens=f\"{path}/tokens.txt\",\nencoder_param=f\"{path}/encoder_jit_trace-pnnx.ncnn.param\",\nencoder_bin=f\"{path}/encoder_jit_trace-pnnx.ncnn.bin\",\ndecoder_param=f\"{path}/decoder_jit_trace-pnnx.ncnn.param\",\ndecoder_bin=f\"{path}/decoder_jit_trace-pnnx.ncnn.bin\",\njoiner_param=f\"{path}/joiner_jit_trace-pnnx.ncnn.param\",\njoiner_bin=f\"{path}/joiner_jit_trace-pnnx.ncnn.bin\",\nnum_threads=4,\n)\nfilename = (\"path/to/your/audio.wav\")\nwith wave.open(filename) as f:\nassert f.getframerate() == recognizer.sample_rate, (\nf.getframerate(),\nrecognizer.sample_rate,\n)\nassert f.getnchannels() == 1, f.getnchannels()\nassert f.getsampwidth() == 2, f.getsampwidth()  # it is in bytes\nnum_samples = f.getnframes()\nsamples = f.readframes(num_samples)\nsamples_int16 = np.frombuffer(samples, dtype=np.int16)\nsamples_float32 = samples_int16.astype(np.float32)\nsamples_float32 = samples_float32 / 32768\nrecognizer.accept_waveform(recognizer.sample_rate, samples_float32)\ntail_paddings = np.zeros(int(recognizer.sample_rate * 0.5), dtype=np.float32)\nrecognizer.accept_waveform(recognizer.sample_rate, tail_paddings)\nrecognizer.input_finished()\nprint(recognizer.text)\n</code></pre>"},{"location":"#example-real-time-recognition-with-a-microphone-python-sherpa-ncnn","title":"Example: Real-time Recognition with a Microphone (Python - Sherpa NCNN)","text":"<p>The following code is adapted from this example. View this example running in our live demo!</p> <pre><code>import sys\nimport sounddevice as sd\nimport sherpa_ncnn\npath = \"./sherpa-ncnn-pruned-transducer-stateless7-streaming-id\"\ndef create_recognizer():\nrecognizer = sherpa_ncnn.Recognizer(\ntokens=f\"{path}/tokens.txt\",\nencoder_param=f\"{path}/encoder_jit_trace-pnnx.ncnn.param\",\nencoder_bin=f\"{path}/encoder_jit_trace-pnnx.ncnn.bin\",\ndecoder_param=f\"{path}/decoder_jit_trace-pnnx.ncnn.param\",\ndecoder_bin=f\"{path}/decoder_jit_trace-pnnx.ncnn.bin\",\njoiner_param=f\"{path}/joiner_jit_trace-pnnx.ncnn.param\",\njoiner_bin=f\"{path}/joiner_jit_trace-pnnx.ncnn.bin\",\nnum_threads=4,\n)\nreturn recognizer\ndef main():\nprint(\"Started! Please speak\")\nrecognizer = create_recognizer()\nsample_rate = recognizer.sample_rate\nsamples_per_read = int(0.1 * sample_rate)  # 0.1 second = 100 ms\nlast_result = \"\"\nwith sd.InputStream(channels=1, dtype=\"float32\", samplerate=sample_rate) as s:\nwhile True:\nsamples, _ = s.read(samples_per_read)  # a blocking read\nsamples = samples.reshape(-1)\nrecognizer.accept_waveform(sample_rate, samples)\nresult = recognizer.text\nif last_result != result:\nlast_result = result\nprint(result)\nif __name__ == \"__main__\":\ndevices = sd.query_devices()\ndefault_input_device_idx = sd.default.device[0]\nprint(f'Use default device: {devices[default_input_device_idx][\"name\"]}')\nmain()\n</code></pre>"},{"location":"#license","title":"License","text":"<p>Our models and inference code are released with Apache-2.0 license. Common Voice and LibriVox Indonesia are released under Public Domain, CC-0. FLEURS is licensed under the Creative Commons license (CC-BY).</p>"},{"location":"#references","title":"References","text":"<pre><code>@inproceedings{commonvoice:2020,\nauthor = {Ardila, R. and Branson, M. and Davis, K. and Henretty, M. and Kohler, M. and Meyer, J. and Morais, R. and Saunders, L. and Tyers, F. M. and Weber, G.},\ntitle = {Common Voice: A Massively-Multilingual Speech Corpus},\nbooktitle = {Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)},\npages = {4211--4215},\nyear = 2020\n}\n</code></pre> <pre><code>@article{fleurs2022arxiv,\ntitle = {FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech},\nauthor = {Conneau, Alexis and Ma, Min and Khanuja, Simran and Zhang, Yu and Axelrod, Vera and Dalmia, Siddharth and Riesa, Jason and Rivera, Clara and Bapna, Ankur},\njournal={arXiv preprint arXiv:2205.12446},\nurl = {https://arxiv.org/abs/2205.12446},\nyear = {2022},\n}\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at team@bookbotkids.com. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"PROJECT_CHARTER/","title":"Project Charter","text":""},{"location":"PROJECT_CHARTER/#vision-statement","title":"Vision statement","text":"<p>Literacy is fundamental, not only for our personal and social development, but also for our ability to function effectively in society. Our vision at Bookbot is that every child should have the opportunity to develop their reading, writing and communication skills to create a happy and successful life.</p>"},{"location":"PROJECT_CHARTER/#mission-statement","title":"Mission statement","text":"<p>Deliver the Bookbot app that combines speech recognition and a scientifically designed reading program for school children to achieve greater literacy and providing better tools for educators to monitor a child\u2019s reading progress. </p>"},{"location":"PROJECT_CHARTER/#community-impact-statement","title":"Community (Impact) statement","text":"<p>Bookbot is founded on the grounds of building a community of learners. Members of the Bookbot community consist of software developers, educators, students, writers, editors, linguists, people with disabilities, and more. We exist to ensure that every child, regardless of their situation, is able to develop their literacy skills.</p>"},{"location":"PROJECT_CHARTER/#licensing-strategy","title":"Licensing strategy","text":"<p>Open source (creative commons), and reseller model for the app. Parts of code are Apache 2</p>"},{"location":"PROJECT_CHARTER/#identification-of-key-trademarks","title":"Identification of key trademarks","text":"<p>No key trademarks</p>"}]}